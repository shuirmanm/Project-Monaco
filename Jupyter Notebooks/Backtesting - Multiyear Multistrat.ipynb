{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f920bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51196f7c",
   "metadata": {},
   "source": [
    "# Historical Odds Import and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed335687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a formula for odds conversion \n",
    "def odds_conversion(x):\n",
    "    if x < 0:\n",
    "        return (-x) / ((-x) + 100) \n",
    "    else: \n",
    "        return (100 / (x + 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccdfb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['70thAnniversary', 'British', 'Spanish', 'Steiermark', 'Hungarian', 'Bahrain', 'Italian', 'Portuguese', 'Austrian', 'Turkish', 'AbuDhabi', 'Belgian', 'EmiliaRomagna', 'Eifel', 'Sakhir', 'Russian']\n",
      "['UnitedStates', 'Brazilian', 'Qatar', 'Azerbaijan', 'British', 'Spanish', 'Hungarian', 'Bahrain', 'Styrian', 'Italian', 'Portuguese', 'Dutch', 'SaudiArabian', 'Austrian', 'Monaco', 'Turkish', 'AbuDhabi', 'Belgian', 'MexicoCity', 'EmiliaRomagna', 'Russian', 'French']\n",
      "['Singapore', 'UnitedStates', 'Canadian', 'Brazilian', 'Miami', 'Azerbaijan', 'British', 'Spanish', 'Australian', 'Hungarian', 'Bahrain', 'Italian', 'Dutch', 'Japanese', 'SaudiArabian', 'Austrian', 'Monaco', 'AbuDhabi', 'Belgian', 'MexicoCity', 'EmiliaRomagna', 'French']\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of all the race file names. This will be used to loop over for importing the data into dataframes\n",
    "# Loops over the years where we have historical data\n",
    "\n",
    "import os \n",
    "\n",
    "year_list = ['2020','2021', '2022']\n",
    "\n",
    "table_dictionary = {}\n",
    "\n",
    "for year in year_list:\n",
    "    \n",
    "    path = '../Raw Data/Odds Data/Historical Odds/'+year\n",
    "    table_list = []\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "\n",
    "        if filename.endswith('.csv'):\n",
    "            table_list.append(filename[:-4])\n",
    "\n",
    "    table_dictionary[year] = table_list\n",
    "    print(table_list)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180cf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV loop\n",
    "# Loops over years\n",
    "\n",
    "odds_df_dict = {}\n",
    "\n",
    "for year in table_dictionary:\n",
    "\n",
    "    odds_df_dict[year] = {}\n",
    "\n",
    "    for race in table_dictionary[year]:\n",
    "        df = pd.read_csv('../Raw Data/Odds Data/Historical Odds/'+year+'/'+race+'.csv',header = 0,sep = '|')\n",
    "        odds_df_dict[year][race] = df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccff8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the odds from American odds format to implied probabilities\n",
    "# There is also some data cleaning for driver names in this loop\n",
    "# Loops over years\n",
    "\n",
    "for year in odds_df_dict:\n",
    "    \n",
    "    for race in odds_df_dict[year]:\n",
    "        try:\n",
    "            odds_df_dict[year][race]['Odds to Win'] = odds_df_dict[year][race]['Odds to Win'].apply(odds_conversion)\n",
    "        except: \n",
    "            pass \n",
    "        try:\n",
    "            odds_df_dict[year][race]['Odds to Finish Top Three'] = odds_df_dict[year][race]['Odds to Finish Top Three'].apply(odds_conversion)\n",
    "        except: \n",
    "            pass         \n",
    "        try:\n",
    "            odds_df_dict[year][race]['Odds to Finish Top Six'] = odds_df_dict[year][race]['Odds to Finish Top Six'].apply(odds_conversion)\n",
    "        except: \n",
    "            pass      \n",
    "        try:\n",
    "            odds_df_dict[year][race]['Odds to Finish Top Ten'] = odds_df_dict[year][race]['Odds to Finish Top Ten'].apply(odds_conversion)\n",
    "        except: \n",
    "            pass\n",
    "            \n",
    "        # Below here is data cleaning - making sure the driver name is consistent across files\n",
    "        odds_df_dict[year][race]['Driver'] = odds_df_dict[year][race]['Driver'].str.replace('Alex Albon','Alexander Albon',regex = True)\n",
    "        odds_df_dict[year][race]['Driver'] = odds_df_dict[year][race]['Driver'].str.replace('Carlos Sainz Jr.','Carlos Sainz',regex = True)\n",
    "        odds_df_dict[year][race]['Driver'] = odds_df_dict[year][race]['Driver'].str.replace('Guanyu Zhou','Zhou Guanyu',regex = True)\n",
    "        odds_df_dict[year][race]['Driver'] = odds_df_dict[year][race]['Driver'].str.replace('Nick Latifi','Nicholas Latifi',regex = True)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c1490",
   "metadata": {},
   "source": [
    "# Importing and Formatting Race Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5fd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing race results, the race information, and driver information\n",
    "\n",
    "results = pd.read_csv('../Raw Data/Historical Race Data/1950_to_2022_CSVs/races.csv',header = 0,sep = ',')\n",
    "races = pd.read_csv('../Raw Data/Historical Race Data/1950_to_2022_CSVs/results.csv',header = 0,sep = ',')\n",
    "drivers = pd.read_csv('../Raw Data/Historical Race Data/1950_to_2022_CSVs/drivers.csv',header = 0,sep = ',')\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for year in year_list:\n",
    "    results_dict[year] = results.loc[results['year'] == int(year)]\n",
    "\n",
    "#results_dict['2021'].head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd774c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for the circuit IDs and race file names\n",
    "# WARNING: commented out races are missing for an unknown reason \n",
    "\n",
    "raceId_dict = {}\n",
    "\n",
    "raceId_dict['2022'] = {'Singapore': 1091, \n",
    "              'UnitedStates': 1093, \n",
    "              'Canadian': 1082, \n",
    "              'Brazilian': 1095, \n",
    "              'Miami': 1078, \n",
    "              'Azerbaijan': 1081, \n",
    "              'British': 1083, \n",
    "              'Spanish': 1079, \n",
    "              'Australian': 1076, \n",
    "              'Hungarian': 1086, \n",
    "              'Bahrain': 1074, \n",
    "              'Italian': 1089, \n",
    "              'Dutch': 1088, \n",
    "              'Japanese': 1092, \n",
    "              'SaudiArabian': 1075, \n",
    "              'Austrian': 1084, \n",
    "              'Monaco': 1080, \n",
    "              'AbuDhabi': 1096, \n",
    "              'Belgian': 1087, \n",
    "              'MexicoCity': 1094, \n",
    "              'EmiliaRomagna': 1077, \n",
    "              'French': 1085}\n",
    "\n",
    "# NOTE: this dictionary will have to be updated with new races for the new year\n",
    "raceId_dict['2021'] = {'Portuguese': 1054, \n",
    "              'Styrian': 1058, \n",
    "              'Austrian': 1060, \n",
    "              'Brazilian': 1071, \n",
    "              'Azerbaijan': 1057, \n",
    "              'British': 1061, \n",
    "              'Spanish': 1055, \n",
    "              'Hungarian': 1062, \n",
    "              'Bahrain': 1052, \n",
    "              'Italian': 1065, \n",
    "              'Dutch': 1064, \n",
    "              'SaudiArabian': 1072, \n",
    "              'AbuDhabi': 1073, \n",
    "              'Monaco': 1056, \n",
    "              'MexicoCity': 1070, \n",
    "              'Belgian': 1063, \n",
    "              'MexicoCity': 1070, \n",
    "              'EmiliaRomagna': 1053, \n",
    "              'French': 1059,\n",
    "              'Russian': 1066,\n",
    "              'Turkish': 1067,\n",
    "              'UnitedStates': 1069,\n",
    "              'Qatar': 1038}\n",
    "\n",
    "raceId_dict['2020'] = {'Portuguese': 1042, \n",
    "              'Styrian': 1032, \n",
    "              'Austrian': 1031,  \n",
    "              'British': 1034, \n",
    "              'Spanish': 1036, \n",
    "              'Hungarian': 1033, \n",
    "              'Bahrain': 1045, \n",
    "              'Italian': 1038, \n",
    "              'AbuDhabi': 1047, \n",
    "              'Belgian': 1037, \n",
    "              'EmiliaRomagna': 1043, \n",
    "              'Russian': 1040,\n",
    "              'Eifel': 1041,\n",
    "              'Tuscan': 1039,\n",
    "              'Turkish': 1044,  \n",
    "              'Sakhir': 1046, \n",
    "              '70thAnniversary': 1035}    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfdefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for the driver Ids and racer names\n",
    "\n",
    "drivers['combined name'] = drivers['forename'] + ' ' + drivers['surname']\n",
    "drivers.head()\n",
    "\n",
    "#drivers.loc[drivers['combined name'].isin(odds_df_dict['Australian']['Driver'])] \n",
    "\n",
    "#NOTE: this list will have to be increased to include the drivers from earlier than 2022\n",
    "driverId_dict = {\n",
    "      'Lewis Hamilton': 1,\n",
    "     'Fernando Alonso': 4,\n",
    "    'Sebastian Vettel': 20,\n",
    "        'Pierre Gasly': 842,\n",
    "    'Daniel Ricciardo': 817,\n",
    "     'Valtteri Bottas': 822,\n",
    "     'Kevin Magnussen': 825,\n",
    "      'Max Verstappen': 830,\n",
    "        'Carlos Sainz': 832,\n",
    "        'Esteban Ocon': 839,\n",
    "        'Lance Stroll': 840,\n",
    "     'Charles Leclerc': 844,\n",
    "        'Lando Norris': 846,\n",
    "      'George Russell': 847,\n",
    "     'Nicholas Latifi': 849,\n",
    "        'Yuki Tsunoda': 852,\n",
    "     'Mick Schumacher': 854,\n",
    "         'Zhou Guanyu': 855,\n",
    "     'Alexander Albon': 848,\n",
    "        'Sergio Perez': 815,\n",
    "     'Nico Hulkenberg': 807\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29d741",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533fafa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Processed Data/Dummy Probability Outputs/Logistic Regression Test/Portuguese.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9f/k8zsnj8s6tvdtxxy4pdk0msr0000gn/T/ipykernel_31140/890026388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpredictions_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraceId_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Processed Data/Dummy Probability Outputs/Logistic Regression Test/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpredictions_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Processed Data/Dummy Probability Outputs/Logistic Regression Test/Portuguese.csv'"
     ]
    }
   ],
   "source": [
    "# Reading the dummy probabilities into a dictionary of dataframes\n",
    "\n",
    "predictions_df_dict = {}\n",
    "\n",
    "for year in year_list:\n",
    "    predictions_df_dict[year] = {}\n",
    "    for race in raceId_dict[year]:\n",
    "        df = pd.read_csv('../Processed Data/Dummy Probability Outputs/Logistic Regression Test/'+race+'.csv',header = 0,sep = ',')\n",
    "        predictions_df_dict[year][race] = df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of converted predictions \n",
    "# Transforming the even weighting dummy file so that it contains odds for 'Odds to Win', 'Odds to Finish Top Three', \n",
    "# 'Odds to Finish Top Six', and 'Odds to Finish Top Ten'\n",
    "\n",
    "converted_predictions_df_dict = {}\n",
    "\n",
    "for year in year_list:\n",
    "\n",
    "    converted_predictions_df_dict[year] = {}\n",
    "\n",
    "    for race in raceId_dict[year]:\n",
    "\n",
    "        converted_predictions_df_dict[year][race] = pd.DataFrame(columns=['Driver','Probability of Winning', \n",
    "                                                        'Probability of Finishing Top Three', \n",
    "                                                        'Probability of Finishing Top Six', \n",
    "                                                        'Probability of Finishing Top Ten'])\n",
    "\n",
    "        converted_predictions_df_dict[year][race]['Driver'] = predictions_df_dict[year][race]['Driver']\n",
    "        converted_predictions_df_dict[year][race]['Probability of Winning'] = predictions_df_dict[year][race]['1']\n",
    "        converted_predictions_df_dict[year][race]['Probability of Finishing Top Three'] = predictions_df_dict[year][race]['1'] + predictions_df_dict[year][race]['2'] + predictions_df_dict[year][race]['3']\n",
    "        converted_predictions_df_dict[year][race]['Probability of Finishing Top Six'] = predictions_df_dict[year][race]['1'] + predictions_df_dict[year][race]['2'] + predictions_df_dict[year][race]['3'] + predictions_df_dict[year][race]['4'] + predictions_df_dict[year][race]['5'] + predictions_df_dict[year][race]['6']\n",
    "        converted_predictions_df_dict[year][race]['Probability of Finishing Top Ten'] = predictions_df_dict[year][race]['1'] + predictions_df_dict[year][race]['2'] + predictions_df_dict[year][race]['3'] + predictions_df_dict[year][race]['4'] + predictions_df_dict[year][race]['5'] + predictions_df_dict[year][race]['6']+ predictions_df_dict[year][race]['7'] + predictions_df_dict[year][race]['8'] + predictions_df_dict[year][race]['9'] + predictions_df_dict[year][race]['10']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dataframe for the backtesting log\n",
    "\n",
    "BacktestingLog = pd.DataFrame(columns=['Year'\n",
    "                                       ,'Race'\n",
    "                                       ,'Driver'\n",
    "                                       , 'Bet placed'\n",
    "                                       , 'Driver race outcome'\n",
    "                                       , 'Implied probability'\n",
    "                                       , 'Estimated probability'\n",
    "                                       , 'Expected value'\n",
    "                                       , 'Bet outcome'\n",
    "                                       , 'Amount wagered'\n",
    "                                       , 'Units won'\n",
    "                                       , 'Net units won'\n",
    "                                       , 'Cumulative bankroll'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e23a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the units wagered function \n",
    "\n",
    "def AmountWageredCalc(UseKellyCriterion,KellyCriterionWeighting,Bankroll,EstimatedOdds,ImpliedOdds):\n",
    "    if Bankroll <= 0: \n",
    "        return 0\n",
    "    elif UseKellyCriterion == 1: \n",
    "        ProportionGained = 1/ImpliedOdds\n",
    "        BankrollPercentage = KellyCriterionWeighting * (EstimatedOdds - (1 - EstimatedOdds)/ProportionGained)\n",
    "        AmountToBet = BankrollPercentage * Bankroll\n",
    "        return round(AmountToBet, 0)\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ae331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions cell \n",
    "# This cell contains assumptions for the betting strategies. It may be deleted or slimmed down over time \n",
    "\n",
    "StartingBankroll = 10000\n",
    "UseKellyCriterion = 1\n",
    "KellyCriterionWeighting = .01\n",
    "\n",
    "Bankroll = StartingBankroll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting different strategies to run: \n",
    "\n",
    "StartingBankroll = 10000\n",
    "Bankroll = StartingBankroll\n",
    "\n",
    "StrategyDict = {\n",
    "    \n",
    "    'SingleUnit':{\n",
    "        'StrategyName':'SingleUnit',\n",
    "        'UseKellyCriterion':0,\n",
    "        'KellyCriterionWeighting':1\n",
    "    },\n",
    "    \n",
    "    'Kelly1Percent':{\n",
    "        'StrategyName':'Kelly1Percent',\n",
    "        'UseKellyCriterion':1,\n",
    "        'KellyCriterionWeighting':.01\n",
    "    },\n",
    "    \n",
    "    'Kelly5Percent':{\n",
    "        'StrategyName':'Kelly5Percent',\n",
    "        'UseKellyCriterion':1,\n",
    "        'KellyCriterionWeighting':.05\n",
    "    },\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BacktestingFunction(StartingBankroll, StrategyName, UseKellyCriterion, KellyCriterionWeighting): \n",
    "\n",
    "    Bankroll = StartingBankroll\n",
    "    \n",
    "    BacktestingLog = pd.DataFrame(columns=['Year'\n",
    "                                       ,'Race'\n",
    "                                       ,'Driver'\n",
    "                                       , 'Bet placed'\n",
    "                                       , 'Driver race outcome'\n",
    "                                       , 'Implied probability'\n",
    "                                       , 'Estimated probability'\n",
    "                                       , 'Expected value'\n",
    "                                       , 'Bet outcome'\n",
    "                                       , 'Amount wagered'\n",
    "                                       , 'Units won'\n",
    "                                       , 'Net units won'\n",
    "                                       , 'Cumulative bankroll'])\n",
    "\n",
    "    \n",
    "    # Creating a triple loop over the year, race, and driver using the implied probability dataframes\n",
    "    # This will perform the backtesting and log the results into a new dataframe\n",
    "\n",
    "    \n",
    "    for year in year_list: \n",
    "\n",
    "        temp = []\n",
    "\n",
    "        for race in raceId_dict[year]:\n",
    "\n",
    "            for driver in odds_df_dict[year][race]['Driver']:\n",
    "\n",
    "\n",
    "                # NOTE: This if statement is for handling two situations where a driver was subbed out last minute \n",
    "                # for another driver. Because this is a rare scenario, I thought it was better to handle these manually \n",
    "                # rather than trying to program something dynamic\n",
    "                if (race == 'Italian' and driver == 'Alexander Albon') or (race == 'SaudiArabian' and driver == 'Sebastian Vettel'):\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "                DriverOutcome = races.loc[((races['driverId'] == driverId_dict[driver]) & (races['raceId'] == raceId_dict[year][race])),'position'] \n",
    "\n",
    "\n",
    "\n",
    "                # NOTE: It is likely possible to replace the four 'comparison' sections with a loop but this was not deemed a priority \n",
    "\n",
    "                #print(race)\n",
    "                #print(driver)\n",
    "                #print(DriverOutcome.iloc[0])\n",
    "\n",
    "                #First comparison - odds to win\n",
    "                ImpliedOdds = odds_df_dict[year][race].loc[odds_df_dict[year][race]['Driver'] == driver,'Odds to Win'] \n",
    "                EstimatedOdds = converted_predictions_df_dict[year][race].loc[converted_predictions_df_dict[year][race]['Driver'] == driver,'Probability of Winning']\n",
    "\n",
    "                #WARNING: This try except is to handle bugs that should be addressed\n",
    "                try:\n",
    "\n",
    "\n",
    "                    if EstimatedOdds.iloc[0] > ImpliedOdds.iloc[0]:\n",
    "\n",
    "\n",
    "                        DriverOutcome = races.loc[((races['driverId'] == driverId_dict[driver]) \n",
    "                                                   & (races['raceId'] == raceId_dict[year][race])),'position']\n",
    "\n",
    "                        BetOutcome = 0\n",
    "                        UnitsWon = 0\n",
    "\n",
    "                        AmountWagered = AmountWageredCalc(UseKellyCriterion,KellyCriterionWeighting,Bankroll,EstimatedOdds.iloc[0],ImpliedOdds.iloc[0])\n",
    "\n",
    "                        if DriverOutcome.iloc[0] == '1':\n",
    "                            BetOutcome = 1\n",
    "                            UnitsWon = AmountWagered / ImpliedOdds.iloc[0]\n",
    "\n",
    "                        NetUnitsWon = UnitsWon - AmountWagered\n",
    "\n",
    "                        Bankroll = Bankroll + NetUnitsWon\n",
    "\n",
    "                        BacktestingLog = pd.concat([BacktestingLog, pd.DataFrame.from_records([{\n",
    "                            'Year': year,\n",
    "                            'Race': race,\n",
    "                            'Driver': driver,\n",
    "                            'Bet placed': 'Odds to Win',\n",
    "                            'Driver race outcome': DriverOutcome.iloc[0],\n",
    "                            'Implied probability': ImpliedOdds.iloc[0], \n",
    "                            'Estimated probability': EstimatedOdds.iloc[0],\n",
    "                            'Expected value': (EstimatedOdds.iloc[0] / ImpliedOdds.iloc[0]) - 1,\n",
    "                            'Bet outcome': BetOutcome,\n",
    "                            'Amount wagered': AmountWagered,\n",
    "                            'Units won': UnitsWon,\n",
    "                            'Net units won': NetUnitsWon,\n",
    "                            'Cumulative bankroll': Bankroll\n",
    "                        }])])\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                #Second comparison - Odds to Finish Top Three\n",
    "                ImpliedOdds = odds_df_dict[year][race].loc[odds_df_dict[year][race]['Driver'] == driver,'Odds to Finish Top Three'] \n",
    "                EstimatedOdds = converted_predictions_df_dict[year][race].loc[converted_predictions_df_dict[year][race]['Driver'] == driver,'Probability of Finishing Top Three']\n",
    "\n",
    "\n",
    "                if EstimatedOdds.iloc[0] > ImpliedOdds.iloc[0]:\n",
    "\n",
    "\n",
    "                    DriverOutcome = races.loc[((races['driverId'] == driverId_dict[driver]) \n",
    "                                               & (races['raceId'] == raceId_dict[year][race])),'position']\n",
    "\n",
    "                    BetOutcome = 0\n",
    "                    UnitsWon = 0\n",
    "\n",
    "                    AmountWagered = AmountWageredCalc(UseKellyCriterion,KellyCriterionWeighting,Bankroll,EstimatedOdds.iloc[0],ImpliedOdds.iloc[0])\n",
    "\n",
    "                    if DriverOutcome.iloc[0] in ['1',  '2', '3']:\n",
    "                        BetOutcome = 1\n",
    "                        UnitsWon = AmountWagered / ImpliedOdds.iloc[0]\n",
    "\n",
    "                    NetUnitsWon = UnitsWon - AmountWagered\n",
    "\n",
    "                    Bankroll = Bankroll + NetUnitsWon\n",
    "\n",
    "                    BacktestingLog = pd.concat([BacktestingLog, pd.DataFrame.from_records([{\n",
    "                        'Year': year,\n",
    "                        'Race': race,\n",
    "                        'Driver': driver,\n",
    "                        'Bet placed': 'Odds to Finish Top Three',\n",
    "                        'Driver race outcome': DriverOutcome.iloc[0],\n",
    "                        'Implied probability': ImpliedOdds.iloc[0], \n",
    "                        'Estimated probability': EstimatedOdds.iloc[0],\n",
    "                        'Expected value': (EstimatedOdds.iloc[0] / ImpliedOdds.iloc[0]) - 1,\n",
    "                        'Bet outcome': BetOutcome,\n",
    "                        'Amount wagered': AmountWagered,\n",
    "                        'Units won': UnitsWon,\n",
    "                        'Net units won': NetUnitsWon, \n",
    "                        'Cumulative bankroll': Bankroll\n",
    "                    }])])            \n",
    "\n",
    "                #Third comparison - Odds to Finish Top Six\n",
    "                ImpliedOdds = odds_df_dict[year][race].loc[odds_df_dict[year][race]['Driver'] == driver,'Odds to Finish Top Six'] \n",
    "                EstimatedOdds = converted_predictions_df_dict[year][race].loc[converted_predictions_df_dict[year][race]['Driver'] == driver,'Probability of Finishing Top Six']\n",
    "\n",
    "\n",
    "                if EstimatedOdds.iloc[0] > ImpliedOdds.iloc[0]:\n",
    "\n",
    "\n",
    "                    DriverOutcome = races.loc[((races['driverId'] == driverId_dict[driver]) \n",
    "                                               & (races['raceId'] == raceId_dict[year][race])),'position']\n",
    "\n",
    "                    BetOutcome = 0\n",
    "                    UnitsWon = 0\n",
    "\n",
    "                    AmountWagered = AmountWageredCalc(UseKellyCriterion,KellyCriterionWeighting,Bankroll,EstimatedOdds.iloc[0],ImpliedOdds.iloc[0])\n",
    "\n",
    "                    if DriverOutcome.iloc[0] in ['1','2','3','4','5','6']:\n",
    "                        BetOutcome = 1\n",
    "                        UnitsWon = AmountWagered / ImpliedOdds.iloc[0]\n",
    "\n",
    "                    NetUnitsWon = UnitsWon - AmountWagered\n",
    "\n",
    "                    Bankroll = Bankroll + NetUnitsWon\n",
    "\n",
    "                    BacktestingLog = pd.concat([BacktestingLog, pd.DataFrame.from_records([{\n",
    "                        'Year': year,\n",
    "                        'Race': race,\n",
    "                        'Driver': driver,\n",
    "                        'Bet placed': 'Odds to Finish Top Six',\n",
    "                        'Driver race outcome': DriverOutcome.iloc[0],\n",
    "                        'Implied probability': ImpliedOdds.iloc[0], \n",
    "                        'Estimated probability': EstimatedOdds.iloc[0],\n",
    "                        'Expected value': (EstimatedOdds.iloc[0] / ImpliedOdds.iloc[0]) - 1,\n",
    "                        'Bet outcome': BetOutcome,\n",
    "                        'Amount wagered': AmountWagered,\n",
    "                        'Units won': UnitsWon,\n",
    "                        'Net units won': NetUnitsWon, \n",
    "                        'Cumulative bankroll': Bankroll\n",
    "                    }])])       \n",
    "\n",
    "                #Fourth comparison - Odds to Finish Top Ten\n",
    "                ImpliedOdds = odds_df_dict[year][race].loc[odds_df_dict[year][race]['Driver'] == driver,'Odds to Finish Top Ten'] \n",
    "                EstimatedOdds = converted_predictions_df_dict[year][race].loc[converted_predictions_df_dict[year][race]['Driver'] == driver,'Probability of Finishing Top Ten']\n",
    "\n",
    "\n",
    "                if EstimatedOdds.iloc[0] > ImpliedOdds.iloc[0]:\n",
    "\n",
    "\n",
    "                    DriverOutcome = races.loc[((races['driverId'] == driverId_dict[driver]) \n",
    "                                               & (races['raceId'] == raceId_dict[year][race])),'position']\n",
    "\n",
    "                    BetOutcome = 0\n",
    "                    UnitsWon = 0\n",
    "\n",
    "                    AmountWagered = AmountWageredCalc(UseKellyCriterion,KellyCriterionWeighting,Bankroll,EstimatedOdds.iloc[0],ImpliedOdds.iloc[0])\n",
    "\n",
    "                    if DriverOutcome.iloc[0] in ['1','2','3','4','5','6','7','8','9','10']:\n",
    "                        BetOutcome = 1\n",
    "                        UnitsWon = AmountWagered / ImpliedOdds.iloc[0]\n",
    "\n",
    "                    NetUnitsWon = UnitsWon - AmountWagered\n",
    "\n",
    "                    Bankroll = Bankroll + NetUnitsWon\n",
    "\n",
    "                    BacktestingLog = pd.concat([BacktestingLog, pd.DataFrame.from_records([{\n",
    "                        'Year': year,\n",
    "                        'Race': race,\n",
    "                        'Driver': driver,\n",
    "                        'Bet placed': 'Odds to Finish Top Ten',\n",
    "                        'Driver race outcome': DriverOutcome.iloc[0],\n",
    "                        'Implied probability': ImpliedOdds.iloc[0], \n",
    "                        'Estimated probability': EstimatedOdds.iloc[0],\n",
    "                        'Expected value': (EstimatedOdds.iloc[0] / ImpliedOdds.iloc[0]) - 1,\n",
    "                        'Bet outcome': BetOutcome,\n",
    "                        'Amount wagered': AmountWagered,\n",
    "                        'Units won': UnitsWon,\n",
    "                        'Net units won': NetUnitsWon, \n",
    "                        'Cumulative bankroll': Bankroll\n",
    "                    }])])        \n",
    "                    \n",
    "    BacktestingLog.to_csv('../Processed Data/Backtesting Results/'+RunName+'/'+StrategyName+'_BackTestingLog.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6232760",
   "metadata": {},
   "source": [
    "## Results summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a77c3",
   "metadata": {},
   "source": [
    "#Running the multiple strategies\n",
    "StartingBankroll = 10000\n",
    "\n",
    "for strategy in StrategyDict:\n",
    "    BacktestingFunction(StartingBankroll, StrategyDict[strategy]['StrategyName']\n",
    "                , StrategyDict[strategy]['UseKellyCriterion'], StrategyDict[strategy]['KellyCriterionWeighting'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047ed57",
   "metadata": {},
   "source": [
    "print('Bets placed: ' + str(BacktestingLog['Bet outcome'].count()))\n",
    "print('Bets won: ' + str(BacktestingLog['Bet outcome'].sum()))\n",
    "print('Net units won: ' + str(BacktestingLog['Net units won'].sum()))\n",
    "\n",
    "print('ROI %: ' + str(\n",
    "    (BacktestingLog['Net units won'].sum() / StartingBankroll) * 100\n",
    "    ))\n",
    "print('\\n')\n",
    "print('Average expected value: ' + str(BacktestingLog['Expected value'].mean()))\n",
    "print('Min expected value: ' + str(BacktestingLog['Expected value'].min()))\n",
    "print('Median expected value: ' + str(BacktestingLog['Expected value'].median()))\n",
    "print('Max expected value: ' + str(BacktestingLog['Expected value'].max()))\n",
    "print('Final bankroll is: ' + str(BacktestingLog['Cumulative bankroll'].tail(1).max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc99eeb",
   "metadata": {},
   "source": [
    "BacktestingLog.to_csv('../Processed Data/Backtesting Results/Multiyear_BackTestingLog.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3f230",
   "metadata": {},
   "source": [
    "BacktestingLog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c93f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing out making new folders\n",
    "newpath = '../Processed Data/Backtesting Results/folder'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One function to rule them all \n",
    "\n",
    "def BacktestingRun(RunName, StartingBankroll): \n",
    "\n",
    "    StrategyDict = {\n",
    "    \n",
    "    'SingleUnit':{\n",
    "        'StrategyName':'SingleUnit',\n",
    "        'UseKellyCriterion':0,\n",
    "        'KellyCriterionWeighting':1\n",
    "    },\n",
    "    \n",
    "    'Kelly1Percent':{\n",
    "        'StrategyName':'Kelly1Percent',\n",
    "        'UseKellyCriterion':1,\n",
    "        'KellyCriterionWeighting':.01\n",
    "    },\n",
    "    \n",
    "    'Kelly5Percent':{\n",
    "        'StrategyName':'Kelly5Percent',\n",
    "        'UseKellyCriterion':1,\n",
    "        'KellyCriterionWeighting':.05\n",
    "    },\n",
    "    \n",
    "}\n",
    "    \n",
    "    if not os.path.exists(RunName):\n",
    "        os.makedirs(RunName)\n",
    "    \n",
    "    for strategy in StrategyDict:\n",
    "        BacktestingFunction(StartingBankroll, StrategyDict[strategy]['StrategyName'], StrategyDict[strategy]['UseKellyCriterion'], StrategyDict[strategy]['KellyCriterionWeighting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637644c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BacktestingRun(\"Multiyear Test\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80b6b7c-672d-4048-860b-18a7e10100c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dummy probabilities into a dictionary of dataframes\n",
    "# This version is not going to work because it isn't reading the drivers in each folder. We have to update it so it does that\n",
    "predictions_df_dict = {}\n",
    "\n",
    "dummy = pd.read_csv('../Processed Data/Dummy Probability Outputs/EvenWeighting.csv',header = 0,sep = ',')\n",
    "\n",
    "for year in year_list:\n",
    "    predictions_df_dict[year] = {}\n",
    "    for race in raceId_dict[year]:\n",
    "        dummy.to_csv('../Processed Data/Dummy Probability Outputs/Even Weighting Multi Year/'+year+'/'+race+'.csv',sep = ',')\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adbf389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to write a version of the above function so that it is grabbing the drivers from the right predictions for the dummy versinos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22950fe3-e788-49b0-b23c-800b9dcb9e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driverId</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>number</th>\n",
       "      <th>code</th>\n",
       "      <th>forename</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>url</th>\n",
       "      <th>combined name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "      <td>Lewis Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>heidfeld</td>\n",
       "      <td>\\N</td>\n",
       "      <td>HEI</td>\n",
       "      <td>Nick</td>\n",
       "      <td>Heidfeld</td>\n",
       "      <td>1977-05-10</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Nick_Heidfeld</td>\n",
       "      <td>Nick Heidfeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>rosberg</td>\n",
       "      <td>6</td>\n",
       "      <td>ROS</td>\n",
       "      <td>Nico</td>\n",
       "      <td>Rosberg</td>\n",
       "      <td>1985-06-27</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Nico_Rosberg</td>\n",
       "      <td>Nico Rosberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>alonso</td>\n",
       "      <td>14</td>\n",
       "      <td>ALO</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>1981-07-29</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Fernando_Alonso</td>\n",
       "      <td>Fernando Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kovalainen</td>\n",
       "      <td>\\N</td>\n",
       "      <td>KOV</td>\n",
       "      <td>Heikki</td>\n",
       "      <td>Kovalainen</td>\n",
       "      <td>1981-10-19</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Heikki_Kovalainen</td>\n",
       "      <td>Heikki Kovalainen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driverId   driverRef number code  forename     surname         dob  \\\n",
       "0         1    hamilton     44  HAM     Lewis    Hamilton  1985-01-07   \n",
       "1         2    heidfeld     \\N  HEI      Nick    Heidfeld  1977-05-10   \n",
       "2         3     rosberg      6  ROS      Nico     Rosberg  1985-06-27   \n",
       "3         4      alonso     14  ALO  Fernando      Alonso  1981-07-29   \n",
       "4         5  kovalainen     \\N  KOV    Heikki  Kovalainen  1981-10-19   \n",
       "\n",
       "  nationality                                             url  \\\n",
       "0     British     http://en.wikipedia.org/wiki/Lewis_Hamilton   \n",
       "1      German      http://en.wikipedia.org/wiki/Nick_Heidfeld   \n",
       "2      German       http://en.wikipedia.org/wiki/Nico_Rosberg   \n",
       "3     Spanish    http://en.wikipedia.org/wiki/Fernando_Alonso   \n",
       "4     Finnish  http://en.wikipedia.org/wiki/Heikki_Kovalainen   \n",
       "\n",
       "       combined name  \n",
       "0     Lewis Hamilton  \n",
       "1      Nick Heidfeld  \n",
       "2       Nico Rosberg  \n",
       "3    Fernando Alonso  \n",
       "4  Heikki Kovalainen  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82e848a1-2a6a-4924-ba46-346911513a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driverId</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>number</th>\n",
       "      <th>code</th>\n",
       "      <th>forename</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>url</th>\n",
       "      <th>combined name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>851</td>\n",
       "      <td>aitken</td>\n",
       "      <td>89</td>\n",
       "      <td>AIT</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Aitken</td>\n",
       "      <td>1995-09-23</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jack_Aitken</td>\n",
       "      <td>Jack Aitken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     driverId driverRef number code forename surname         dob nationality  \\\n",
       "849       851    aitken     89  AIT     Jack  Aitken  1995-09-23     British   \n",
       "\n",
       "                                          url combined name  \n",
       "849  http://en.wikipedia.org/wiki/Jack_Aitken   Jack Aitken  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers.loc[drivers['surname'] == 'Aitken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f5064-cb78-4410-b83a-494c9da2c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['2020'].head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f348d75-4cfa-41b8-9dca-a776990c0713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driverId</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>number</th>\n",
       "      <th>code</th>\n",
       "      <th>forename</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>url</th>\n",
       "      <th>combined name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>826</td>\n",
       "      <td>kvyat</td>\n",
       "      <td>26</td>\n",
       "      <td>KVY</td>\n",
       "      <td>Daniil</td>\n",
       "      <td>Kvyat</td>\n",
       "      <td>1994-04-26</td>\n",
       "      <td>Russian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Daniil_Kvyat</td>\n",
       "      <td>Daniil Kvyat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     driverId driverRef number code forename surname         dob nationality  \\\n",
       "825       826     kvyat     26  KVY   Daniil   Kvyat  1994-04-26     Russian   \n",
       "\n",
       "                                           url combined name  \n",
       "825  http://en.wikipedia.org/wiki/Daniil_Kvyat  Daniil Kvyat  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers.loc[drivers['forename'] == 'Daniil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d955da5-fb67-4725-951a-82fea1a7ded7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
